{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import cPickle\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "from multiprocessing import cpu_count\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants define\n",
    "ROOT_PATH = '../'\n",
    "ONLINE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'label'\n",
    "train_len = 4999\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################### Helper function ###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log(info):\n",
    "    print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + ' ' + str(info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_feat_count(df, df_feat, columns_groupby, new_column_name, type='int'):\n",
    "    df_count = pd.DataFrame(df_feat.groupby(columns_groupby).size()).fillna(0).astype(type).reset_index()\n",
    "    df_count.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(df_count, on=columns_groupby, how='left')\n",
    "    return df, [new_column_name]\n",
    "\n",
    "def merge_feat_onehot_count(df, df_feat, columns_groupby, prefix, type='int'):\n",
    "    df_count = df_feat.groupby(columns_groupby).size().unstack().fillna(0).astype(type).reset_index()\n",
    "    df_count.columns = [i if i == columns_groupby[0] else prefix + '_' + str(i) for i in df_count.columns]\n",
    "    df = df.merge(df_count, on=columns_groupby[0], how='left')\n",
    "    return df, list(np.delete(df_count.columns.values, 0))\n",
    "\n",
    "def merge_feat_nunique(df, df_feat, columns_groupby, column, new_column_name, type='int'):\n",
    "    df_nunique = pd.DataFrame(df_feat.groupby(columns_groupby)[column].nunique()).fillna(0).astype(type).reset_index()\n",
    "    df_nunique.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(df_nunique, on=columns_groupby, how='left')\n",
    "    return df, [new_column_name]\n",
    "\n",
    "def merge_feat_min(df, df_feat, columns_groupby, column, new_column_name, type='float'):\n",
    "    df_min = pd.DataFrame(df_feat.groupby(columns_groupby)[column].min()).fillna(0).astype(type).reset_index()\n",
    "    df_min.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(df_min, on=columns_groupby, how='left')\n",
    "    return df, [new_column_name]\n",
    "\n",
    "def merge_feat_max(df, df_feat, columns_groupby, column, new_column_name, type='float'):\n",
    "    df_max = pd.DataFrame(df_feat.groupby(columns_groupby)[column].max()).fillna(0).astype(type).reset_index()\n",
    "    df_max.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(df_max, on=columns_groupby, how='left')\n",
    "    return df, [new_column_name]\n",
    "\n",
    "def merge_feat_mean(df, df_feat, columns_groupby, column, new_column_name, type='float'):\n",
    "    df_mean = pd.DataFrame(df_feat.groupby(columns_groupby)[column].mean()).fillna(0).astype(type).reset_index()\n",
    "    df_mean.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(df_mean, on=columns_groupby, how='left')\n",
    "    return df, [new_column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_auc_f1(preds, dtrain):\n",
    "    df = pd.DataFrame({'y_true': dtrain.get_label(), 'y_score': preds})\n",
    "    df['y_pred'] = df['y_score'].apply(lambda x: 1 if x >= threshold else 0)\n",
    "    auc = metrics.roc_auc_score(df.y_true, df.y_score)\n",
    "    f1 = metrics.f1_score(df.y_true, df.y_pred)\n",
    "    return 'feval', (auc * 0.6 + f1 * 0.4), True\n",
    "\n",
    "def lgb_cv(train_x, train_y, params, rounds, folds):\n",
    "    start = time.clock()\n",
    "    log(str(train_x.columns))\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    log('run cv: ' + 'round: ' + str(rounds))\n",
    "    res = lgb.cv(params, dtrain, rounds, nfold=folds, \n",
    "                 metrics=['eval_auc_f1', 'auc'], feval=eval_auc_f1, \n",
    "                 early_stopping_rounds=200, verbose_eval=5)\n",
    "    elapsed = (time.clock() - start)\n",
    "    log('Time used:' + str(elapsed) + 's')\n",
    "    # return len(res['auc-mean']), res['auc-mean'][len(res['auc-mean']) - 1]\n",
    "    return len(res['feval-mean']), res['feval-mean'][len(res['feval-mean']) - 1], res['auc-mean'][len(res['auc-mean']) - 1]\n",
    "\n",
    "def lgb_train_predict(train_x, train_y, test_x, params, rounds):\n",
    "    start = time.clock()\n",
    "    log(str(train_x.columns))\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    valid_sets = [dtrain]\n",
    "    model = lgb.train(params, dtrain, rounds, valid_sets, feval=eval_auc_f1, verbose_eval=5)\n",
    "    pred = model.predict(test_x)\n",
    "    elapsed = (time.clock() - start)\n",
    "    log('Time used:' + str(elapsed) + 's')\n",
    "    return model, pred\n",
    "\n",
    "def store_result(test_index, pred, threshold, name):\n",
    "    result = pd.DataFrame({'uid': test_index, 'prob': pred})\n",
    "    result = result.sort_values('prob', ascending=False)\n",
    "    result['label'] = 0\n",
    "    result.loc[result.prob > threshold, 'label'] = 1\n",
    "    result.to_csv('../data/output/sub/' + name + '.csv', index=0, header=0, columns=['uid', 'label'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################### Read data ###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(ROOT_PATH + 'data/input/train/uid_train.txt', header=None, sep='\\t')\n",
    "train.columns = ['uid', 'label']\n",
    "train_voice = pd.read_csv(ROOT_PATH + 'data/input/train/voice_train.txt', header=None, sep='\\t')\n",
    "train_voice.columns = ['uid', 'opp_num', 'opp_head', 'opp_len', 'start_time', 'end_time', 'call_type', 'in_out']\n",
    "train_sms = pd.read_csv(ROOT_PATH + 'data/input/train/sms_train.txt', header=None, sep='\\t')\n",
    "train_sms.columns = ['uid', 'opp_num', 'opp_head', 'opp_len', 'start_time', 'in_out']\n",
    "train_wa = pd.read_csv(ROOT_PATH + 'data/input/train/wa_train.txt', header=None, sep='\\t')\n",
    "train_wa.columns = ['uid', 'wa_name', 'visit_cnt', 'visit_dura', 'up_flow', 'down_flow', 'wa_type', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'uid': ['u' + str(i) for i in range(5000, 7000)]})\n",
    "test_voice = pd.read_csv(ROOT_PATH + 'data/input/test_a/voice_test_a.txt', header=None, sep='\\t')\n",
    "test_voice.columns = ['uid', 'opp_num', 'opp_head', 'opp_len', 'start_time', 'end_time', 'call_type', 'in_out']\n",
    "test_sms = pd.read_csv(ROOT_PATH + 'data/input/test_a/sms_test_a.txt', header=None, sep='\\t')\n",
    "test_sms.columns = ['uid', 'opp_num', 'opp_head', 'opp_len', 'start_time', 'in_out']\n",
    "test_wa = pd.read_csv(ROOT_PATH + 'data/input/test_a/wa_test_a.txt', header=None, sep='\\t')\n",
    "test_wa.columns = ['uid', 'wa_name', 'visit_cnt', 'visit_dura', 'up_flow', 'down_flow', 'wa_type', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([train, test]).reset_index(drop=True)\n",
    "df_voice = pd.concat([train_voice, test_voice]).reset_index(drop=True)\n",
    "df_sms = pd.concat([train_sms, test_sms]).reset_index(drop=True)\n",
    "df_wa = pd.concat([train_wa, test_wa]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################### Preprocess ###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# backup data\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################### Feature engineer ###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset data\n",
    "df = df_copy.copy()\n",
    "predictors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df, predictors_tmp = merge_feat_count(df, df_voice, ['uid'], 'count_gb_uid_in_voice'); predictors += predictors_tmp\n",
    "df, predictors_tmp = merge_feat_count(df, df_sms, ['uid'], 'count_gb_uid_in_sms'); predictors += predictors_tmp\n",
    "df, predictors_tmp = merge_feat_count(df, df_wa, ['uid'], 'count_gb_uid_in_wa'); predictors += predictors_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df, predictors_tmp = merge_feat_onehot_count(df, df_voice, ['uid', 'opp_len'], 'voice_opp_len'); predictors += predictors_tmp\n",
    "df, predictors_tmp = merge_feat_onehot_count(df, df_voice, ['uid', 'call_type'], 'voice_call_type'); predictors += predictors_tmp\n",
    "df, predictors_tmp = merge_feat_onehot_count(df, df_voice, ['uid', 'in_out'], 'voice_in_out_'); predictors += predictors_tmp\n",
    "df, predictors_tmp = merge_feat_onehot_count(df, df_sms, ['uid', 'opp_len'], 'sms_opp_len'); predictors += predictors_tmp\n",
    "df, predictors_tmp = merge_feat_onehot_count(df, df_sms, ['uid', 'in_out'], 'sms_in_out'); predictors += predictors_tmp\n",
    "df, predictors_tmp = merge_feat_onehot_count(df, df_wa, ['uid', 'wa_type'], 'wa_type'); predictors += predictors_tmp\n",
    "df, predictors_tmp = merge_feat_onehot_count(df, df_wa, ['uid', 'date'], 'wa_date'); predictors += predictors_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df, predictors_tmp = merge_feat_nunique(df, df_voice, ['uid'], 'opp_num', 'nunique_oppNum_gb_uid_in_voice'); predictors += predictors_tmp\n",
    "df, predictors_tmp = merge_feat_nunique(df, df_voice, ['uid'], 'opp_head', 'nunique_oppHead_gb_uid_in_voice'); predictors += predictors_tmp\n",
    "df, predictors_tmp = merge_feat_nunique(df, df_sms, ['uid'], 'opp_num', 'nunique_oppNum_gb_uid_in_sms'); predictors += predictors_tmp\n",
    "df, predictors_tmp = merge_feat_nunique(df, df_sms, ['uid'], 'opp_head', 'nunique_oppHead_gb_uid_in_sms'); predictors += predictors_tmp\n",
    "df, predictors_tmp = merge_feat_nunique(df, df_wa, ['uid'], 'wa_name', 'nunique_waName_gb_uid_in_wa'); predictors += predictors_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_list = ['visit_cnt', 'visit_dura', 'up_flow', 'down_flow']\n",
    "for i in col_list:\n",
    "    df, predictors_tmp = merge_feat_min(df, df_wa, ['uid'], i, 'min_%s_gb_uid_in_wa' % i); predictors += predictors_tmp\n",
    "    df, predictors_tmp = merge_feat_max(df, df_wa, ['uid'], i, 'max_%s_gb_uid_in_wa' % i); predictors += predictors_tmp\n",
    "    df, predictors_tmp = merge_feat_mean(df, df_wa, ['uid'], i, 'mean_%s_gb_uid_in_wa' % i); predictors += predictors_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = df.loc[:(train_len - 1), predictors]\n",
    "train_y = df.loc[:(train_len - 1), target]\n",
    "test_x = df.loc[train_len:, predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################### LightGBM ###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_lgb = {\n",
    "    'rounds': 10000,\n",
    "    'folds': 5\n",
    "}\n",
    "\n",
    "params_lgb = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'auc'},\n",
    "    'num_leaves': 63,\n",
    "    'learning_rate': 0.06,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    # 'min_sum_hessian_in_leaf': 10,\n",
    "    'verbosity': 5,\n",
    "    'num_threads': cpu_count() - 1,\n",
    "    'seed': 7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-23 14:27:06 Index([u'count_gb_uid_in_voice', u'count_gb_uid_in_sms', u'count_gb_uid_in_wa',\n",
      "       u'voice_opp_len_3', u'voice_opp_len_5', u'voice_opp_len_6',\n",
      "       u'voice_opp_len_7', u'voice_opp_len_8', u'voice_opp_len_9',\n",
      "       u'voice_opp_len_10',\n",
      "       ...\n",
      "       u'mean_visit_cnt_gb_uid_in_wa', u'min_visit_dura_gb_uid_in_wa',\n",
      "       u'max_visit_dura_gb_uid_in_wa', u'mean_visit_dura_gb_uid_in_wa',\n",
      "       u'min_up_flow_gb_uid_in_wa', u'max_up_flow_gb_uid_in_wa',\n",
      "       u'mean_up_flow_gb_uid_in_wa', u'min_down_flow_gb_uid_in_wa',\n",
      "       u'max_down_flow_gb_uid_in_wa', u'mean_down_flow_gb_uid_in_wa'],\n",
      "      dtype='object', length=114)\n",
      "2018-05-23 14:27:06 run cv: round: 10000\n",
      "[5]\tcv_agg's feval: 0.742857 + 0.00647818\tcv_agg's auc: 0.885253 + 0.0068806\n",
      "[10]\tcv_agg's feval: 0.751567 + 0.00811904\tcv_agg's auc: 0.895535 + 0.00534308\n",
      "[15]\tcv_agg's feval: 0.754651 + 0.00758081\tcv_agg's auc: 0.898279 + 0.00518307\n",
      "[20]\tcv_agg's feval: 0.756208 + 0.00968548\tcv_agg's auc: 0.899436 + 0.00523651\n",
      "[25]\tcv_agg's feval: 0.754246 + 0.0083986\tcv_agg's auc: 0.901049 + 0.00483545\n",
      "[30]\tcv_agg's feval: 0.757557 + 0.00695869\tcv_agg's auc: 0.901886 + 0.0054094\n",
      "[35]\tcv_agg's feval: 0.760936 + 0.00663429\tcv_agg's auc: 0.90275 + 0.00565346\n",
      "[40]\tcv_agg's feval: 0.766301 + 0.00364038\tcv_agg's auc: 0.904489 + 0.00597859\n",
      "[45]\tcv_agg's feval: 0.764457 + 0.00478261\tcv_agg's auc: 0.905906 + 0.0051928\n",
      "[50]\tcv_agg's feval: 0.767857 + 0.006041\tcv_agg's auc: 0.907087 + 0.00583665\n",
      "[55]\tcv_agg's feval: 0.768825 + 0.00640461\tcv_agg's auc: 0.907926 + 0.0062232\n",
      "[60]\tcv_agg's feval: 0.768607 + 0.00499413\tcv_agg's auc: 0.908376 + 0.00607369\n",
      "[65]\tcv_agg's feval: 0.772332 + 0.00432158\tcv_agg's auc: 0.908743 + 0.00580687\n",
      "[70]\tcv_agg's feval: 0.770811 + 0.00511285\tcv_agg's auc: 0.909189 + 0.00635901\n",
      "[75]\tcv_agg's feval: 0.771928 + 0.00539969\tcv_agg's auc: 0.909549 + 0.00609244\n",
      "[80]\tcv_agg's feval: 0.769063 + 0.00311532\tcv_agg's auc: 0.90947 + 0.00622436\n",
      "[85]\tcv_agg's feval: 0.771638 + 0.00690494\tcv_agg's auc: 0.909935 + 0.00640448\n",
      "[90]\tcv_agg's feval: 0.772406 + 0.00726893\tcv_agg's auc: 0.909893 + 0.00650867\n",
      "[95]\tcv_agg's feval: 0.773524 + 0.00323246\tcv_agg's auc: 0.909721 + 0.00633293\n",
      "[100]\tcv_agg's feval: 0.769188 + 0.00457502\tcv_agg's auc: 0.909549 + 0.0063443\n",
      "[105]\tcv_agg's feval: 0.771275 + 0.0057108\tcv_agg's auc: 0.909691 + 0.00649553\n",
      "[110]\tcv_agg's feval: 0.769468 + 0.00347003\tcv_agg's auc: 0.909729 + 0.00634228\n",
      "[115]\tcv_agg's feval: 0.772425 + 0.00522954\tcv_agg's auc: 0.909733 + 0.00594918\n",
      "[120]\tcv_agg's feval: 0.771289 + 0.00598198\tcv_agg's auc: 0.909579 + 0.0060263\n",
      "[125]\tcv_agg's feval: 0.769765 + 0.00670893\tcv_agg's auc: 0.909562 + 0.00615338\n",
      "[130]\tcv_agg's feval: 0.771371 + 0.00777956\tcv_agg's auc: 0.909566 + 0.00621867\n",
      "[135]\tcv_agg's feval: 0.770959 + 0.00614938\tcv_agg's auc: 0.909459 + 0.00629977\n",
      "[140]\tcv_agg's feval: 0.772929 + 0.00603519\tcv_agg's auc: 0.909443 + 0.00627971\n",
      "[145]\tcv_agg's feval: 0.771153 + 0.00637834\tcv_agg's auc: 0.909172 + 0.00623683\n",
      "[150]\tcv_agg's feval: 0.772082 + 0.00668194\tcv_agg's auc: 0.909234 + 0.00655275\n",
      "[155]\tcv_agg's feval: 0.769648 + 0.0066538\tcv_agg's auc: 0.908949 + 0.00671233\n",
      "[160]\tcv_agg's feval: 0.769971 + 0.00739882\tcv_agg's auc: 0.908731 + 0.00658249\n",
      "[165]\tcv_agg's feval: 0.772255 + 0.0078117\tcv_agg's auc: 0.908909 + 0.00679705\n",
      "[170]\tcv_agg's feval: 0.771796 + 0.0070132\tcv_agg's auc: 0.908692 + 0.00659868\n",
      "[175]\tcv_agg's feval: 0.770566 + 0.00825333\tcv_agg's auc: 0.908949 + 0.00660343\n",
      "[180]\tcv_agg's feval: 0.771831 + 0.00624129\tcv_agg's auc: 0.909176 + 0.00670285\n",
      "[185]\tcv_agg's feval: 0.772526 + 0.00705387\tcv_agg's auc: 0.909162 + 0.0065965\n",
      "[190]\tcv_agg's feval: 0.771702 + 0.00770842\tcv_agg's auc: 0.909134 + 0.006491\n",
      "[195]\tcv_agg's feval: 0.770459 + 0.00668754\tcv_agg's auc: 0.908894 + 0.00641474\n",
      "[200]\tcv_agg's feval: 0.771477 + 0.00608233\tcv_agg's auc: 0.908807 + 0.00646041\n",
      "[205]\tcv_agg's feval: 0.771355 + 0.00549084\tcv_agg's auc: 0.908531 + 0.00607879\n",
      "[210]\tcv_agg's feval: 0.770422 + 0.00686606\tcv_agg's auc: 0.90844 + 0.00611326\n",
      "[215]\tcv_agg's feval: 0.771121 + 0.005395\tcv_agg's auc: 0.908425 + 0.00636499\n",
      "[220]\tcv_agg's feval: 0.770315 + 0.0070466\tcv_agg's auc: 0.908634 + 0.00621983\n",
      "[225]\tcv_agg's feval: 0.769506 + 0.00594241\tcv_agg's auc: 0.908535 + 0.00639558\n",
      "[230]\tcv_agg's feval: 0.767967 + 0.00671612\tcv_agg's auc: 0.908643 + 0.00626169\n",
      "[235]\tcv_agg's feval: 0.767152 + 0.00625278\tcv_agg's auc: 0.908617 + 0.0063703\n",
      "[240]\tcv_agg's feval: 0.767391 + 0.00578763\tcv_agg's auc: 0.908463 + 0.0063835\n",
      "[245]\tcv_agg's feval: 0.767523 + 0.0062208\tcv_agg's auc: 0.908593 + 0.00617414\n",
      "[250]\tcv_agg's feval: 0.768981 + 0.00737087\tcv_agg's auc: 0.90859 + 0.00634767\n",
      "[255]\tcv_agg's feval: 0.768074 + 0.00435245\tcv_agg's auc: 0.908603 + 0.00628008\n",
      "[260]\tcv_agg's feval: 0.767352 + 0.0054591\tcv_agg's auc: 0.90842 + 0.00651799\n",
      "[265]\tcv_agg's feval: 0.766473 + 0.00457529\tcv_agg's auc: 0.90822 + 0.00635953\n",
      "[270]\tcv_agg's feval: 0.767371 + 0.00445511\tcv_agg's auc: 0.908252 + 0.00649912\n",
      "[275]\tcv_agg's feval: 0.768742 + 0.00411195\tcv_agg's auc: 0.908161 + 0.00648289\n",
      "[280]\tcv_agg's feval: 0.770389 + 0.00356628\tcv_agg's auc: 0.908303 + 0.00642394\n",
      "[285]\tcv_agg's feval: 0.769524 + 0.00423912\tcv_agg's auc: 0.908601 + 0.00633487\n",
      "2018-05-23 14:27:18 Time used:11.7854863581s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88, 0.77428177607176119, 0.90982089004040212)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_cv(train_x, train_y, params_lgb, config_lgb['rounds'], config_lgb['folds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-23 14:27:29 Index([u'count_gb_uid_in_voice', u'count_gb_uid_in_sms', u'count_gb_uid_in_wa',\n",
      "       u'voice_opp_len_3', u'voice_opp_len_5', u'voice_opp_len_6',\n",
      "       u'voice_opp_len_7', u'voice_opp_len_8', u'voice_opp_len_9',\n",
      "       u'voice_opp_len_10',\n",
      "       ...\n",
      "       u'mean_visit_cnt_gb_uid_in_wa', u'min_visit_dura_gb_uid_in_wa',\n",
      "       u'max_visit_dura_gb_uid_in_wa', u'mean_visit_dura_gb_uid_in_wa',\n",
      "       u'min_up_flow_gb_uid_in_wa', u'max_up_flow_gb_uid_in_wa',\n",
      "       u'mean_up_flow_gb_uid_in_wa', u'min_down_flow_gb_uid_in_wa',\n",
      "       u'max_down_flow_gb_uid_in_wa', u'mean_down_flow_gb_uid_in_wa'],\n",
      "      dtype='object', length=114)\n",
      "[5]\ttraining's auc: 0.957986\ttraining's feval: 0.865289\n",
      "[10]\ttraining's auc: 0.967644\ttraining's feval: 0.88754\n",
      "[15]\ttraining's auc: 0.972187\ttraining's feval: 0.902914\n",
      "[20]\ttraining's auc: 0.976475\ttraining's feval: 0.914456\n",
      "[25]\ttraining's auc: 0.982036\ttraining's feval: 0.92596\n",
      "[30]\ttraining's auc: 0.985603\ttraining's feval: 0.936038\n",
      "[35]\ttraining's auc: 0.988494\ttraining's feval: 0.945155\n",
      "[40]\ttraining's auc: 0.99102\ttraining's feval: 0.950862\n",
      "[45]\ttraining's auc: 0.993294\ttraining's feval: 0.959312\n",
      "[50]\ttraining's auc: 0.995357\ttraining's feval: 0.966445\n",
      "[55]\ttraining's auc: 0.9969\ttraining's feval: 0.971037\n",
      "[60]\ttraining's auc: 0.997972\ttraining's feval: 0.976703\n",
      "[65]\ttraining's auc: 0.99865\ttraining's feval: 0.98001\n",
      "[70]\ttraining's auc: 0.999289\ttraining's feval: 0.984911\n",
      "[75]\ttraining's auc: 0.9996\ttraining's feval: 0.98863\n",
      "[80]\ttraining's auc: 0.999793\ttraining's feval: 0.992192\n",
      "[85]\ttraining's auc: 0.999924\ttraining's feval: 0.994327\n",
      "[90]\ttraining's auc: 0.999968\ttraining's feval: 0.995037\n",
      "2018-05-23 14:27:30 Time used:1.11024408946s\n"
     ]
    }
   ],
   "source": [
    "model_lgb, pred_lgb = lgb_train_predict(train_x, train_y, test_x, params_lgb, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = store_result(test.uid, pred_lgb, threshold, '20180523-lgb-%d-%d(r%d)' % (7742, 9098, 90))\n",
    "result = store_result(test.uid, pred_lgb, threshold, 'submission')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp = pd.DataFrame({'feature':train_x.columns.values, 'importance':list(model_lgb.feature_importance())})\n",
    "imp = imp.sort_values(by = 'importance', ascending = False)\n",
    "imp.to_csv(ROOT_PATH + 'data/output/feat_imp/imp-20180523-%d-%d(r%d).csv' % (7742, 9098, 90), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
